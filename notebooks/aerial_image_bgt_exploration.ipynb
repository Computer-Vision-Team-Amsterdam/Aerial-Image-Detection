{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Prepare image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# if input image is in range 0..1, please first multiply img by 255\n",
    "# assume image is ndarray of shape [height, width, channels] where channels can be 1, 3 or 4\n",
    "def imshow(img):\n",
    "    import IPython\n",
    "    _,ret = cv2.imencode('.jpg', img) \n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)\n",
    "\n",
    "all_classes = {\n",
    "    0: \"plane\",\n",
    "    1: \"ship\",\n",
    "    2: \"storage tank\",\n",
    "    3: \"baseball diamond\",\n",
    "    4: \"tennis court\",\n",
    "    5: \"basketball court\",\n",
    "    6: \"ground track field\",\n",
    "    7: \"harbor\",\n",
    "    8: \"bridge\",\n",
    "    9: \"large vehicle\",\n",
    "    10: \"small vehicle\",\n",
    "    11: \"helicopter\",\n",
    "    12: \"roundabout\",\n",
    "    13: \"soccer ball field\",\n",
    "    14: \"swimming pool\",\n",
    "}\n",
    "\n",
    "classes_to_keep = [9, 10]\n",
    "classes_to_exclude = [class_id for class_id in all_classes.keys() if class_id not in classes_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_path = f\"../datasets/experiments/luchtfotos/beeldmateriaal.nl/2025_115000_487000_RGB_JPEG_hrl.tif\"\n",
    "\n",
    "rd_x = 115000\n",
    "rd_y = 487000\n",
    "\n",
    "cm_per_px = 8\n",
    "\n",
    "full_image = cv2.imread(full_image_path)\n",
    "print(f\"Image shape: {full_image.shape}\")\n",
    "\n",
    "full_image_m = (full_image.shape[0] * cm_per_px) / 100\n",
    "print(f\"({full_image_m}m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = 0\n",
    "start_y = 0\n",
    "\n",
    "image_size_px = 1024 * 4\n",
    "\n",
    "part_image = full_image[\n",
    "    start_y:start_y+image_size_px, \n",
    "    start_x:start_x+image_size_px\n",
    "]\n",
    "\n",
    "start_x_m = (start_x * cm_per_px) / 100\n",
    "start_y_m = (start_y * cm_per_px) / 100\n",
    "image_size_m = (image_size_px * cm_per_px) / 100\n",
    "\n",
    "part_area = [\n",
    "    rd_x + start_x_m, \n",
    "    rd_y + full_image_m - start_y_m - image_size_m, \n",
    "    rd_x + start_x_m + image_size_m, \n",
    "    rd_y + full_image_m - start_y_m\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(part_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"../datasets/experiments/model_weights/yolo11m-obb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the model\n",
    "yolo_result = model(part_image, conf=0.2, classes=classes_to_keep, agnostic_nms=True)[0]  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obb_boxes = yolo_result.obb.xyxyxyxy\n",
    "obb_cls = yolo_result.obb.cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## SAHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_prediction, get_sliced_prediction\n",
    "\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type='ultralytics',\n",
    "    model_path=\"../datasets/experiments/model_weights/yolo11m-obb.pt\", # any yolov8/yolov9/yolo11/yolo12/rt-detr det model is supported\n",
    "    confidence_threshold=0.2,\n",
    "    device=\"cpu\", # or 'cuda:0' if GPU is available\n",
    "    image_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sahi_result = get_prediction(np.flip(part_image, 2), detection_model, exclude_classes_by_id=classes_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sahi_result.export_visuals(export_dir=\"../datasets/experiments/\", file_name=\"sample1_sahi_1\", hide_labels=True, hide_conf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sahi_result = get_sliced_prediction(\n",
    "    np.flip(part_image, 2),\n",
    "    detection_model,\n",
    "    # slice_height = 512,\n",
    "    # slice_width = 512,\n",
    "    slice_height = 1024,\n",
    "    slice_width = 1024,\n",
    "    overlap_height_ratio = 0.1,\n",
    "    overlap_width_ratio = 0.1,\n",
    "    exclude_classes_by_id=classes_to_exclude,\n",
    "    postprocess_class_agnostic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sahi_result.export_visuals(export_dir=\"../datasets/experiments/\", file_name=\"sahi_test_1\", hide_labels=True, hide_conf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Convert SAHI result to YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "obb_boxes = np.concatenate([[np.reshape(pred.mask.segmentation, [4, 2]) for pred in sahi_result.object_prediction_list]]).tolist()\n",
    "obb_cls = np.array([int(pred.category.id) for pred in sahi_result.object_prediction_list]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Visualize bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "obb_names = model.names\n",
    "obb_image = np.ascontiguousarray(part_image)\n",
    "\n",
    "ann = Annotator(\n",
    "    obb_image,\n",
    "    line_width=None,  # default auto-size\n",
    "    font_size=None,  # default auto-size\n",
    "    font=\"Arial.ttf\",  # must be ImageFont compatible\n",
    "    pil=False,  # use PIL, otherwise uses OpenCV\n",
    ")\n",
    "for (i, cls_idx) in enumerate(obb_cls):\n",
    "    obb = obb_boxes[i]\n",
    "    # label = f\"{obb_names.get(int(cls_idx))}\"\n",
    "    ann.box_label(\n",
    "        box=obb,\n",
    "        # label=label,\n",
    "        # color=colors(cls_idx, True),\n",
    "        color=(0, 180, 255),\n",
    "    )\n",
    "\n",
    "image_with_obb = ann.result()\n",
    "\n",
    "imshow(image_with_obb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../datasets/experiments/bigger_sahi_512.jpg\"\n",
    "\n",
    "cv2.imwrite(filename=filename, img=image_with_obb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Convert bounding boxes to GPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely.geometry as sg\n",
    "\n",
    "RD_crs = \"EPSG:28992\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier = cm_per_px / 100\n",
    "transformation_matrix = [multiplier, 0, 0, -multiplier, part_area[0], part_area[1]+image_size_m]\n",
    "\n",
    "obb_geoms = gpd.GeoSeries(data=[sg.Polygon(coords) for coords in obb_boxes]).affine_transform(transformation_matrix)\n",
    "\n",
    "detections_gdf = gpd.GeoDataFrame(\n",
    "    data={\n",
    "        \"class_id\": obb_cls,\n",
    "        \"geometry\": obb_geoms\n",
    "    },\n",
    "    crs=RD_crs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## BGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely.geometry as sg\n",
    "\n",
    "bgt_wegdeel = gpd.read_file(\"../datasets/experiments/bgt/115000_487000/bgt_wegdeel.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_wegdeel.function.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_wegdeel = bgt_wegdeel[bgt_wegdeel[\"eindRegistratie\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_voetpad = bgt_wegdeel[bgt_wegdeel.function.isin(['voetpad', 'fietspad', 'voetpad op trap', 'voetgangersgebied'])]\n",
    "area_poly = sg.box(*part_area)\n",
    "bgt_voetpad_area = bgt_voetpad.intersection(area_poly)\n",
    "bgt_voetpad_area = bgt_voetpad_area[~bgt_voetpad_area.is_empty]\n",
    "bgt_voetpad_area.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_parkeervlak = bgt_wegdeel[bgt_wegdeel.function.isin(['parkeervlak'])]\n",
    "bgt_parkeervlak_area = bgt_parkeervlak.intersection(area_poly)\n",
    "bgt_parkeervlak_area = bgt_parkeervlak_area[~bgt_parkeervlak_area.is_empty]\n",
    "bgt_parkeervlak_area.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "padding = 10\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10), constrained_layout=True)\n",
    "\n",
    "[x_min, y_min, x_max, y_max] = map(int, part_area)\n",
    "\n",
    "bgt_voetpad_area.plot(ax=ax, color=\"red\", alpha=0.25)\n",
    "bgt_parkeervlak_area.plot(ax=ax, color=\"green\", alpha=0.25)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "\n",
    "ax.set_xticks(range(x_min, x_max+1, 100))\n",
    "ax.set_xticklabels(range(x_min, x_max+1, 100))\n",
    "ax.set_yticks(range(y_min, y_max+1, 100))\n",
    "ax.set_yticklabels(range(y_min, y_max+1, 100))\n",
    "\n",
    "ax.set_xlim((x_min - padding, x_max + padding))\n",
    "ax.set_ylim((y_min - padding, y_max + padding))\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.savefig(\"../datasets/experiments/bigger_bgt.jpg\", bbox_inches=extent, dpi=450)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Compute wrongly parked cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_gdf[\"percentage_on_sidewalk\"] = (\n",
    "    detections_gdf.intersection(bgt_voetpad_area.union_all(method=\"unary\")).area \n",
    "    / detections_gdf.area\n",
    ")\n",
    "detections_gdf[\"wrongly_parked\"] = detections_gdf[\"percentage_on_sidewalk\"] >= 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Visualise all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "padding = 10\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10), constrained_layout=True)\n",
    "\n",
    "[x_min, y_min, x_max, y_max] = map(int, part_area)\n",
    "\n",
    "ax.imshow(np.flip(part_image, 2), extent=[x_min, x_max, y_min, y_max])\n",
    "\n",
    "bgt_voetpad_area.plot(ax=ax, color=\"red\", alpha=0.25)\n",
    "bgt_parkeervlak_area.plot(ax=ax, color=\"green\", alpha=0.25)\n",
    "detections_gdf[~detections_gdf[\"wrongly_parked\"]].boundary.plot(ax=ax, color=np.array([255, 180, 0]) / 255)\n",
    "detections_gdf[detections_gdf[\"wrongly_parked\"]].boundary.plot(ax=ax, color=np.array([255, 0, 189]) / 255)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "\n",
    "ax.set_xticks(range(x_min, x_max+1, 100))\n",
    "ax.set_xticklabels(range(x_min, x_max+1, 100))\n",
    "ax.set_yticks(range(y_min, y_max+1, 100))\n",
    "ax.set_yticklabels(range(y_min, y_max+1, 100))\n",
    "\n",
    "ax.set_xlim((x_min - padding, x_max + padding))\n",
    "ax.set_ylim((y_min - padding, y_max + padding))\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.savefig(\"../datasets/experiments/bigger_combined.jpg\", bbox_inches=extent, dpi=450)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aerial-Image-Detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
